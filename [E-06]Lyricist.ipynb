{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "542e4cb0",
   "metadata": {},
   "source": [
    "## 데이터 읽어오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b6ec88b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "데이터 크기: 187088\n",
      "Examples:\n",
      " ['', '', '[Spoken Intro:]']\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import os, re\n",
    "import tensorflow as tf\n",
    "\n",
    "txt_file_path = os.getenv('HOME')+'/aiffel/lyricist/data/lyrics/*'\n",
    "\n",
    "# txt_file_path 경로에 있는 모든 파일명을 리스트 형식으로 txt_list 에 할당\n",
    "txt_list = glob.glob(txt_file_path)\n",
    "\n",
    "raw_corpus = []\n",
    "\n",
    "# 여러개의 txt 파일을 모두 읽어서 raw_corpus 에 담습니다.\n",
    "for txt_file in txt_list:\n",
    "    with open(txt_file, \"r\") as f:\n",
    "        # read() : 파일 전체의 내용을 하나의 문자열로 읽어온다. \n",
    "        # splitlines()  : 여러라인으로 구분되어 있는 문자열을 한라인씩 분리하여 리스트로 반환\n",
    "        raw = f.read().splitlines()\n",
    "        # extend() : 리스트함수로 추가적인 내용을 연장 한다.\n",
    "        raw_corpus.extend(raw)\n",
    "\n",
    "print(\"데이터 크기:\", len(raw_corpus))\n",
    "print(\"Examples:\\n\", raw_corpus[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "131e4df6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 :  \n",
      "1 :  \n",
      "2 :  [Spoken Intro:]\n",
      "3 :  You ever want something \n",
      "4 :  that you know you shouldn't have \n",
      "5 :  The more you know you shouldn't have it, \n",
      "6 :  The more you want it \n",
      "7 :  And then one day you get it, \n",
      "8 :  It's so good too \n",
      "9 :  But it's just like my girl \n",
      "10 :  When she's around me \n",
      "11 :  I just feel so good, so good \n",
      "12 :  But right now I just feel cold, so cold \n",
      "13 :  Right down to my bones \n",
      "14 :  'Cause ooh... \n",
      "15 :  Ain't no sunshine when she's gone \n",
      "16 :  It's not warm when she's away \n",
      "17 :  Ain't no sunshine when she's gone \n",
      "18 :  And she's always gone too long \n",
      "19 :  Anytime she goes away \n"
     ]
    }
   ],
   "source": [
    "for i in range(20):\n",
    "    print(i, ': ', raw_corpus[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0c23dd46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You ever want something \n",
      "that you know you shouldn't have \n",
      "The more you know you shouldn't have it, \n",
      "The more you want it \n",
      "And then one day you get it, \n",
      "It's so good too \n",
      "But it's just like my girl \n",
      "When she's around me \n",
      "I just feel so good, so good \n",
      "But right now I just feel cold, so cold \n",
      "Right down to my bones \n",
      "'Cause ooh... \n",
      "Ain't no sunshine when she's gone \n",
      "It's not warm when she's away \n",
      "Ain't no sunshine when she's gone \n",
      "And she's always gone too long \n",
      "Anytime she goes away \n"
     ]
    }
   ],
   "source": [
    "# enumerate() 함수를 이용하여 raw_corpus list 내에 저장된 문장과\n",
    "# 그 문장읜 인덱스를 반환 (인덱스, 문장 순)\n",
    "for idx, sentence in enumerate(raw_corpus):\n",
    "    # 길리가 0인 문장은 건너뜁니다.\n",
    "    if len(sentence) == 0: continue\n",
    "    # 문장의 끝이 ] 인 문장은 건너뜁니다.\n",
    "    if sentence[-1] == \"]\": continue\n",
    "    # 문장 20개만 확인.\n",
    "    if idx > 19: break\n",
    "        \n",
    "    print(sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc2812d9",
   "metadata": {},
   "source": [
    "## 데이터 정제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "91e56194",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_sentence(sentence):\n",
    "    sentence = sentence.lower().strip()\n",
    "    sentence = re.sub(r\"([?.!,])\", r\" \\1 \", sentence)\n",
    "    sentence = re.sub(r'[\" \"]+',\" \", sentence)\n",
    "    sentence = re.sub(r\"[^a-zA-Z?.!,]+\", \" \", sentence)\n",
    "    sentence = sentence.strip()\n",
    "    sentence = '<start> ' + sentence + ' <end>'\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b86f7f4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<start> this is sample sentence . <end>\n"
     ]
    }
   ],
   "source": [
    "# 필터링 잘 적용됬는지 확인.\n",
    "print(preprocess_sentence(\"This @_is ;;;sample          sentence.\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "698d7d42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 필터링된 문장 저장.\n",
    "corpus = []\n",
    "\n",
    "# raw_corpus list에 저장된 문장들을 순서대로 반환하여 sentence에 저장\n",
    "for sentence in raw_corpus:\n",
    "    # 우리가 원하지 않는 문장은 건너뜁니다.\n",
    "    if len(sentence) == 0: continue\n",
    "    if sentence[-1] == \"]\": continue\n",
    "    \n",
    "    # 앞서 구현한 preprocess_sentence() 함수를 이용하여 문장을 정제 하고 저장합니다.\n",
    "    preprocessed_sentence = preprocess_sentence(sentence)\n",
    "    corpus.append(preprocessed_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "63510654",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<start> you ever want something <end>',\n",
       " '<start> that you know you shouldn t have <end>',\n",
       " '<start> the more you know you shouldn t have it , <end>',\n",
       " '<start> the more you want it <end>',\n",
       " '<start> and then one day you get it , <end>',\n",
       " '<start> it s so good too <end>',\n",
       " '<start> but it s just like my girl <end>',\n",
       " '<start> when she s around me <end>',\n",
       " '<start> i just feel so good , so good <end>',\n",
       " '<start> but right now i just feel cold , so cold <end>']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91069d4a",
   "metadata": {},
   "source": [
    "## 평가 데이터셋 분리"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e8af733",
   "metadata": {},
   "source": [
    "훈련 데이터와 평가 데이터를 분리하세요!\n",
    "\n",
    "tokenize() 함수로 데이터를 Tensor로 변환한 후, sklearn 모듈의 train_test_split() 함수를 사용해 훈련 데이터와 평가 데이터를 분리하도록 하겠습니다. 단어장의 크기는 12,000 이상 으로 설정하세요! 총 데이터의 20% 를 평가 데이터셋으로 사용해 주세요!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "97f7721e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  2   7 156 ...   0   0   0]\n",
      " [  2  17   7 ...   0   0   0]\n",
      " [  2   6  98 ...   0   0   0]\n",
      " ...\n",
      " [  2 310   1 ...   0   0   0]\n",
      " [  2 729   5 ...   0   0   0]\n",
      " [  2 729   5 ...   0   0   0]] <keras_preprocessing.text.Tokenizer object at 0x7fd1e42e0a90>\n"
     ]
    }
   ],
   "source": [
    "def tokenize(corpus):\n",
    "    # 15,000 단어를 기억할 수 있는 tokenizer를 생성\n",
    "    tokenizer = tf.keras.preprocessing.text.Tokenizer(num_words=15000, filters=' ', oov_token=\"<unk>\")\n",
    "    \n",
    "    # corpus를 이용해 tokenizer 내부의 단어장을 완성.\n",
    "    # tokenizer.fit_on_texts(texts): 문자 데이터를 입력받아 리스트의 형태로 변환하는 메서드\n",
    "    tokenizer.fit_on_texts(corpus)\n",
    "    \n",
    "    # 준비한 tokenizer를 이용해 corpus를 Tensor로 변환합니다.\n",
    "    # tokenizer.texts_to_sequences(texts): 텍스트 안의 단어들을 숫자의 시퀀스 형태로 변환하는 메서드\n",
    "    tensor = tokenizer.texts_to_sequences(corpus)\n",
    "    \n",
    "    # 입력 데이터의 시퀀스 길이를 일정하게 맞춰줍니다.\n",
    "    # 만약 시퀀스가 짧다면 문장 뒤에 패딩을 붙여 길이를 맞춰줍니다.\n",
    "    # 문장 앞에 패딩을 붙여 길이를 맞추고 싶다면 padding='pre'를 사용합니다.\n",
    "    tensor = tf.keras.preprocessing.sequence.pad_sequences(tensor, padding='post', maxlen=20)\n",
    "    \n",
    "    print(tensor, tokenizer)\n",
    "    return tensor, tokenizer\n",
    "\n",
    "tensor, tokenizer = tokenize(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "db783116",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   2    7  156   62  199    3    0    0    0    0]\n",
      " [   2   17    7   34    7 1536   15   76    3    0]\n",
      " [   2    6   98    7   34    7 1536   15   76   11]]\n"
     ]
    }
   ],
   "source": [
    "# 생성된 텐서 데이터 확인.\n",
    "print(tensor[:3, :10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ae32fc08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 : <unk>\n",
      "2 : <start>\n",
      "3 : <end>\n",
      "4 : ,\n",
      "5 : i\n",
      "6 : the\n",
      "7 : you\n",
      "8 : and\n",
      "9 : a\n",
      "10 : to\n"
     ]
    }
   ],
   "source": [
    "# tokenizer.index_word: 현재 계산된 단어의 인덱스와 인덱스에 해당하는 단어를 dictionary 형태로 반환\n",
    "for idx in tokenizer.index_word:\n",
    "    print(idx, \":\", tokenizer.index_word[idx])\n",
    "    \n",
    "    if idx >= 10: break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3165de2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  2   7 156  62 199   3   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0]\n",
      "[  7 156  62 199   3   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0]\n"
     ]
    }
   ],
   "source": [
    "# tensor에서 마지막 토큰을 잘라서 소스 문장을 생성, 해당 토큰은 <end>가 아니라 <pad>일 가능성 높음.\n",
    "src_input = tensor[:, :-1]\n",
    "# tenor에서 <start>를 잘라내서 타겟 문장을 생성.\n",
    "tgt_input = tensor[:, 1:]\n",
    "\n",
    "print(src_input[0])\n",
    "print(tgt_input[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db6e570c",
   "metadata": {},
   "source": [
    "훈련 데이터와 평가데이터로 분리하기!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f9c949ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# 소스문장을 train으로 타겟 문장을 val로.\n",
    "enc_train, enc_val, dec_train, dec_val = train_test_split(src_input, tgt_input, random_state=2023, test_size= 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dc11084e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(139790, 19) (34948, 19) (139790, 19) (34948, 19)\n"
     ]
    }
   ],
   "source": [
    "print(enc_train.shape, enc_val.shape, dec_train.shape, dec_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d0fcd66a",
   "metadata": {},
   "outputs": [],
   "source": [
    "BUFFER_SIZE = len(src_input)\n",
    "BATCH_SIZE = 256\n",
    "steps_per_epoch = len(src_input) // BATCH_SIZE\n",
    "\n",
    "# tokenizer가 구축한 단어사전 내 15000개와, 여기 포함되지 않은 0:<pad>를 포함하여 15001개\n",
    "# tokenizer.num_words: 주어진 데이터의 문장들에서 빈도수가 높은 n개의 단어만 선택\n",
    "# tokenize() 함수에서 num_words를 15000개로 선언했기 때문에, tokenizer.num_words의 값은 15000개\n",
    "VOCAB_SIZE = tokenizer.num_words + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "63b3f4e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BatchDataset shapes: ((256, 19), (256, 19)), types: (tf.int32, tf.int32)>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset = tf.data.Dataset.from_tensor_slices((enc_train, dec_train))\n",
    "train_dataset = train_dataset.shuffle(BUFFER_SIZE)\n",
    "train_dataset = train_dataset.batch(BATCH_SIZE, drop_remainder = True)\n",
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a37d2c5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BatchDataset shapes: ((256, 19), (256, 19)), types: (tf.int32, tf.int32)>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset = tf.data.Dataset.from_tensor_slices((enc_val, dec_val))\n",
    "test_dataset = test_dataset.shuffle(BUFFER_SIZE)\n",
    "test_dataset = test_dataset.batch(BATCH_SIZE, drop_remainder=True)\n",
    "test_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b073e50",
   "metadata": {},
   "source": [
    "## Step 5. 인공지능 만들기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a68e8a6",
   "metadata": {},
   "source": [
    "모델의 Embedding Size와 Hidden Size를 조절하며 10 Epoch 안에 val_loss 값을 2.2 수준으로 줄일 수 있는 모델을 설계하세요!\n",
    "\n",
    "잘 설계한 모델을 학습하려면, model.fit() 함수를 사용해야 합니다. model.fit() 함수에는 다양한 인자를 넣어주어야 하는데, 가장 기본적인 인자로는 데이터셋과 epochs가 있습니다. '5. 실습 (2) 인공지능 학습시키기'에서의 예시와 같이 말이죠.\n",
    "\n",
    "model.fit(dataset, epochs=30)\n",
    "하지만 model.fit() 함수의 epochs를 아무리 크게 넣는다 해도 val_loss 값은 2.2 아래로 떨어지지 않습니다. 이럴 경우는 batch size를 변경하는 것과 같이 model.fit() 함수에 다양한 인자를 넣어주면 해결될 수도 있습니다. 자세한 내용은 https://www.tensorflow.org/api_docs/python/tf/keras/Model#fit 를 참고하세요!\n",
    "\n",
    "Loss는 아래 제시된 Loss 함수를 그대로 사용하세요!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8b5c90fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextGenerator(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_size, hidden_size):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Embedding 레이어, 2개의 LSTM 레이어, 1개의 Dense 레이어로 구성되어 있다.\n",
    "        # Embedding 레이어는 단어 사전의 인덱스 값을 해당 인덱스 번째의 워드 벡터로 바꿔준다.\n",
    "        # 이 워드 벡터는 의미 벡터 공간에서 단어의 추상적 표현으로 사용된다.\n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_size)\n",
    "        self.rnn_1 = tf.keras.layers.LSTM(hidden_size, return_sequences=True)\n",
    "        self.rnn_2 = tf.keras.layers.LSTM(hidden_size, return_sequences=True)\n",
    "        self.linear = tf.keras.layers.Dense(vocab_size)\n",
    "    \n",
    "    def call(self, x):\n",
    "        out = self.embedding(x)\n",
    "        out = self.rnn_1(out)\n",
    "        out = self.rnn_2(out)\n",
    "        out = self.linear(out)\n",
    "        \n",
    "        return out\n",
    "# embedding size 값이 커질 수록 단어의 추상적인 특징들을 더 잡아낼 수 있지만,\n",
    "# 데이터의 양이 적으면 긍정적인 결과가 나오지 않을 수 있다.\n",
    "# 워드 벡터의 차원수를 말하며 단어가 추상적으로 표현되는 크기입니다.\n",
    "embedding_size = 512\n",
    "hidden_size = 2048\n",
    "lyricist = TextGenerator(tokenizer.num_words + 1, embedding_size, hidden_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b1ba7bd8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(256, 19, 15001), dtype=float32, numpy=\n",
       "array([[[ 2.63942820e-05, -8.18772824e-05, -9.79509859e-05, ...,\n",
       "         -9.91337220e-05,  8.78163264e-05,  1.43919518e-04],\n",
       "        [ 4.57413145e-04, -2.39000467e-04, -1.94939930e-04, ...,\n",
       "         -3.82338214e-04,  8.75895275e-05,  3.94405288e-06],\n",
       "        [ 5.61957771e-04, -5.75165730e-04, -5.69165044e-04, ...,\n",
       "         -4.62788768e-04,  3.71017697e-04, -9.13665863e-05],\n",
       "        ...,\n",
       "        [-5.40264184e-04, -1.55906717e-03, -9.80683952e-04, ...,\n",
       "         -1.47486699e-03, -1.78612221e-03, -2.16201297e-03],\n",
       "        [-5.89596399e-04, -1.48225785e-03, -9.18462407e-04, ...,\n",
       "         -1.48213841e-03, -2.21425015e-03, -2.22714082e-03],\n",
       "        [-6.46775705e-04, -1.41686795e-03, -8.59385065e-04, ...,\n",
       "         -1.47831161e-03, -2.60963780e-03, -2.25203903e-03]],\n",
       "\n",
       "       [[ 2.63942820e-05, -8.18772824e-05, -9.79509859e-05, ...,\n",
       "         -9.91337220e-05,  8.78163264e-05,  1.43919518e-04],\n",
       "        [-2.07133315e-04, -4.04570106e-04, -1.44081772e-04, ...,\n",
       "          9.96215604e-05, -1.67095059e-05,  2.33135404e-04],\n",
       "        [-4.28421889e-04, -3.42319283e-04, -3.13259661e-04, ...,\n",
       "         -7.44051940e-05,  5.44190225e-05, -1.56933675e-04],\n",
       "        ...,\n",
       "        [-7.08994514e-04, -1.24777295e-03, -9.06864007e-04, ...,\n",
       "         -1.39522064e-03, -2.19788821e-03, -2.07360904e-03],\n",
       "        [-8.09208141e-04, -1.27647223e-03, -8.51757533e-04, ...,\n",
       "         -1.37621455e-03, -2.55496334e-03, -2.10804376e-03],\n",
       "        [-9.02891043e-04, -1.30146206e-03, -8.03351169e-04, ...,\n",
       "         -1.35773711e-03, -2.88641267e-03, -2.11487082e-03]],\n",
       "\n",
       "       [[ 2.63942820e-05, -8.18772824e-05, -9.79509859e-05, ...,\n",
       "         -9.91337220e-05,  8.78163264e-05,  1.43919518e-04],\n",
       "        [ 1.18716707e-04, -1.71965919e-04,  1.34507223e-04, ...,\n",
       "         -7.44009230e-05, -9.72521593e-05,  6.60865568e-04],\n",
       "        [ 2.71609839e-04,  1.55873131e-04,  3.24935419e-04, ...,\n",
       "          1.95810208e-04,  4.06001600e-05,  9.16033052e-04],\n",
       "        ...,\n",
       "        [-7.21290766e-04, -1.22063432e-03, -8.28849850e-04, ...,\n",
       "         -1.35209190e-03, -2.92697619e-03, -1.50934735e-03],\n",
       "        [-7.98024761e-04, -1.22621923e-03, -8.01036891e-04, ...,\n",
       "         -1.37463305e-03, -3.19168088e-03, -1.59755896e-03],\n",
       "        [-8.74628371e-04, -1.23361300e-03, -7.76207366e-04, ...,\n",
       "         -1.38684409e-03, -3.43364500e-03, -1.65496429e-03]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[ 2.63942820e-05, -8.18772824e-05, -9.79509859e-05, ...,\n",
       "         -9.91337220e-05,  8.78163264e-05,  1.43919518e-04],\n",
       "        [ 3.32301890e-04, -1.23769671e-04, -2.30534410e-04, ...,\n",
       "         -2.56702973e-04, -2.60177621e-04,  2.21719529e-04],\n",
       "        [ 5.59017411e-04, -1.46378705e-04, -3.37598816e-04, ...,\n",
       "         -1.48718187e-04, -4.52852692e-04,  9.45296415e-05],\n",
       "        ...,\n",
       "        [-8.49975913e-04, -1.25504076e-03, -7.30618078e-04, ...,\n",
       "         -1.92091078e-03, -2.98830820e-03, -2.20266217e-03],\n",
       "        [-8.90899682e-04, -1.25375006e-03, -6.96010771e-04, ...,\n",
       "         -1.85110653e-03, -3.27171851e-03, -2.15698383e-03],\n",
       "        [-9.37700155e-04, -1.25499198e-03, -6.69679546e-04, ...,\n",
       "         -1.78506807e-03, -3.52696655e-03, -2.10179947e-03]],\n",
       "\n",
       "       [[ 2.63942820e-05, -8.18772824e-05, -9.79509859e-05, ...,\n",
       "         -9.91337220e-05,  8.78163264e-05,  1.43919518e-04],\n",
       "        [-5.60464741e-06, -4.65932826e-04, -1.85332130e-04, ...,\n",
       "         -5.10210702e-05,  2.14404601e-04, -8.36788749e-05],\n",
       "        [ 9.78284224e-05, -7.66262412e-04, -2.68196134e-04, ...,\n",
       "         -2.60530796e-04,  2.93348538e-04, -4.10856330e-04],\n",
       "        ...,\n",
       "        [-1.00042648e-03, -1.34629931e-03, -6.18597900e-04, ...,\n",
       "         -1.57685648e-03, -3.76218441e-03, -2.21853843e-03],\n",
       "        [-1.06934807e-03, -1.34829234e-03, -6.18797028e-04, ...,\n",
       "         -1.55475643e-03, -3.96598643e-03, -2.14840611e-03],\n",
       "        [-1.13449269e-03, -1.35594013e-03, -6.20027713e-04, ...,\n",
       "         -1.53244671e-03, -4.14380757e-03, -2.07604142e-03]],\n",
       "\n",
       "       [[ 2.63942820e-05, -8.18772824e-05, -9.79509859e-05, ...,\n",
       "         -9.91337220e-05,  8.78163264e-05,  1.43919518e-04],\n",
       "        [-8.74908219e-05,  7.19054588e-05, -3.34309269e-04, ...,\n",
       "         -1.97944391e-04,  1.63206380e-04, -1.08019485e-04],\n",
       "        [-5.58295760e-05,  3.52254778e-04, -5.09396370e-04, ...,\n",
       "         -2.91211414e-04,  2.04144526e-04, -3.94037750e-04],\n",
       "        ...,\n",
       "        [-8.60714528e-04, -1.10240490e-03, -1.12858543e-03, ...,\n",
       "         -1.45790249e-03, -3.21280002e-03, -2.31894990e-03],\n",
       "        [-9.14291712e-04, -1.13962672e-03, -1.04352063e-03, ...,\n",
       "         -1.42464961e-03, -3.46182380e-03, -2.26325449e-03],\n",
       "        [-9.71005124e-04, -1.17486168e-03, -9.68378561e-04, ...,\n",
       "         -1.39584334e-03, -3.68451164e-03, -2.19810731e-03]]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 데이터셋에서 데이터 한 배치만 가져와서 모델에 넣어서 확인.\n",
    "for src_sample, tgt_sample in train_dataset.take(1): break\n",
    "\n",
    "lyricist(src_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f0935798",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"text_generator\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        multiple                  7680512   \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  multiple                  20979712  \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                multiple                  33562624  \n",
      "_________________________________________________________________\n",
      "dense (Dense)                multiple                  30737049  \n",
      "=================================================================\n",
      "Total params: 92,959,897\n",
      "Trainable params: 92,959,897\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 모델 구조 확인.\n",
    "lyricist.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "090da9e5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "546/546 [==============================] - 398s 724ms/step - loss: 2.8304 - val_loss: 2.4917\n",
      "Epoch 2/10\n",
      "546/546 [==============================] - 394s 722ms/step - loss: 2.3564 - val_loss: 2.2918\n",
      "Epoch 3/10\n",
      "546/546 [==============================] - 395s 722ms/step - loss: 2.1332 - val_loss: 2.1556\n",
      "Epoch 4/10\n",
      "546/546 [==============================] - 395s 723ms/step - loss: 1.9244 - val_loss: 2.0528\n",
      "Epoch 5/10\n",
      "546/546 [==============================] - 396s 725ms/step - loss: 1.7230 - val_loss: 1.9710\n",
      "Epoch 6/10\n",
      "546/546 [==============================] - 396s 724ms/step - loss: 1.5315 - val_loss: 1.9104\n",
      "Epoch 7/10\n",
      "546/546 [==============================] - 396s 725ms/step - loss: 1.3527 - val_loss: 1.8644\n",
      "Epoch 8/10\n",
      "546/546 [==============================] - 395s 723ms/step - loss: 1.1902 - val_loss: 1.8372\n",
      "Epoch 9/10\n",
      "546/546 [==============================] - 395s 724ms/step - loss: 1.0479 - val_loss: 1.8276\n",
      "Epoch 10/10\n",
      "546/546 [==============================] - 396s 725ms/step - loss: 0.9301 - val_loss: 1.8276\n"
     ]
    }
   ],
   "source": [
    "# optimizer로는 사용빈도가 높은 Adam으로 선택.\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "\n",
    "# 훈련 데이터의 라벨이 정수의 형태로 제공될 때, 사용하는 손실함수.\n",
    "loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True, reduction='none')\n",
    "# from_logits 의 기본값은 False. 모델에 의해 생성된 출력 값이 정규화되지 않았음을 손실 함수에 알려줌.\n",
    "# 즉, softmax 함수가 적용되지 않았다는걸 의미.\n",
    "# reduction 의 기본값은 SUM. 각자 나오는 값의 반환을 원할 때, None을 사용.\n",
    "\n",
    "lyricist.compile(loss=loss, optimizer=optimizer)\n",
    "history = lyricist.fit(train_dataset, validation_data=test_dataset, epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20d49f3a",
   "metadata": {},
   "source": [
    "데이터가 커서 훈련하는 데 시간이 제법 걸릴 겁니다.(한 epoch 당 3 분 이상) 여유를 가지고 작업하시면 좋아요 :)\n",
    "\n",
    "마지막으로 멋진 모델이 생성한 가사 한 줄을 제출하시길 바랍니다!\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c032a814",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 문장생성 함수 정의\n",
    "# 모델에게 시작 문장을 전달하면 시작 문장을 바탕으로 작문을 진행.\n",
    "# 시작 문자열을 init_sentence 로 받으며, 디폴트 값은 <start> 를 받음.\n",
    "def generate_text(model, tokenizer, init_sentence=\"<start>\", max_len=20):\n",
    "    # 테스트를 위해, 입력 받은 init_sentence로 텐서로 변환.\n",
    "    # 텍스트 안의 단어들을 숫자의 시퀀스의 형태로 변환.\n",
    "    test_input = tokenizer.texts_to_sequences([init_sentence])\n",
    "    test_tensor = tf.convert_to_tensor(test_input, dtype=tf.int64)\n",
    "    end_token = tokenizer.word_index[\"<end>\"]\n",
    "    \n",
    "    # 단어 하나씩 예측해 문장을 생성\n",
    "    # 1. 입력받은 문장의 텐서를 입력.\n",
    "    # 2. 예측된 값 중 가장 높은 확률인 word index를 뽑아냄.\n",
    "    # 3. 2에서 예측된 word index를 문장 뒤에 붙임.\n",
    "    # 4. 모델이 <end>를 예측햇거나, max_len에 도달했다면 문장 생성을 마침.\n",
    "    # 루프를 돌면서 init_sentence에 단어를 하나씩 생성\n",
    "    while True:\n",
    "        # 1\n",
    "        predict = model(test_tensor)\n",
    "        # 2\n",
    "        predict_word = tf.argmax(tf.nn.softmax(predict, axis=-1), axis=-1)[:, -1]\n",
    "        # 3\n",
    "        test_tensor = tf.concat([test_tensor, tf.expand_dims(predict_word, axis=0)], axis=-1)\n",
    "        # 4\n",
    "        if predict_word.numpy()[0] == end_token: break\n",
    "        if test_tensor.shape[1] >= max_len: break\n",
    "    \n",
    "    generated = \"\"\n",
    "    # tokenizer를 이용해 word index를 단어로 하나씩 변환합니다.\n",
    "    for word_index in test_tensor[0].numpy():\n",
    "        generated += tokenizer.index_word[word_index] + \" \"\n",
    "    \n",
    "    # 모델이 생성한 문장을 반환.\n",
    "    return generated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9bd6f9af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<start> i love you <end> '"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_text(lyricist, tokenizer, init_sentence=\"<start> i love\", max_len=20)\n",
    "# generate_text 함수에 lyricist 라 정의한 모델을 이용해서 ilove 로 시작되는 문장을 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f80bd885",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<start> i do not like <end> '"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_text(lyricist, tokenizer, init_sentence=\"<start> i do\", max_len=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b48d72b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<start> i have a little husband , <end> '"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_text(lyricist, tokenizer, init_sentence=\"<start> i have\", max_len=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a61b235c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<start> i want to get in the zone if you really want to party <end> '"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_text(lyricist, tokenizer, init_sentence=\"<start> i want\", max_len=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "bfe00ce1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<start> your love is fadin <end> '"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_text(lyricist, tokenizer, init_sentence=\"<start> your\", max_len=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0f5eb050",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.legend(['training', 'validation'], loc='lower right')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
